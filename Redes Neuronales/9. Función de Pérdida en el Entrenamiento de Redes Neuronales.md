# 9. Función de Pérdida en el Entrenamiento de Redes Neuronales
En este capítulo se abordará la función de pérdida, que es utilizada en el entrenamiento de redes neuronales para evaluar la discrepancia entre las predicciones del modelo y los valores reales. Se explorarán dos funciones de pérdida comunes: el error cuadrático medio (MSE) y la entropía cruzada (cross-entropy). Se explicará cómo se calculan y su relevancia en diferentes tareas de aprendizaje.

## 9.1 ¿Qué es la función de pérdida en el entrenamiento de redes neuronales?

La función de pérdida, también conocida como función de costo, es una métrica que mide cuánto difieren las predicciones de nuestra red neuronal de los valores reales. En términos más simples, cuantifica cuán "equivocada" está nuestra red en sus predicciones.

### Conceptos clave

#### Función de Pérdida

La función de pérdida es la herramienta que utilizamos para medir cuán bien una red neuronal puede predecir el resultado esperado. Se calcula tomando la diferencia entre los valores predichos por la red y los valores objetivos reales.

**Ejemplo:** Piensa en aprender a lanzar dardos con el objetivo de dar siempre en el centro del tablero. Cada vez que lanzas un dardo, puede que no golpee exactamente el centro. La función de pérdida, en este caso, sería la distancia entre donde tu dardo golpea y el centro del tablero. Cuanto menor sea esta distancia, mejor será tu lanzamiento.

#### Error Cuadrático Medio (MSE)

El Error Cuadrático Medio (MSE) es una función de pérdida comúnmente utilizada en problemas de regresión. Se calcula como el promedio de las diferencias cuadradas entre los valores predichos y los valores reales.

**Ejemplo introductorio:** Siguiendo con el juego de dardos, imagina que mides el error cuadrando la distancia del dardo al centro. Esto significa que los errores grandes (dardos lejos del centro) se penalizan más que los errores pequeños.

#### Entropía Cruzada (Cross-Entropy)

La Entropía Cruzada es otra función de pérdida que se utiliza a menudo en problemas de clasificación. Mide la divergencia entre las probabilidades predichas por la red y los valores reales.

**Ejemplo introductorio:** Piensa en un juego de adivinar la carta. La entropía cruzada mide cuán lejos están tus conjeturas (predicciones) de la realidad. Si adivinas correctamente con alta confianza, la entropía cruzada es baja. Pero si tu confianza está mal dirigida, la entropía cruzada es alta.

A través de estas funciones de pérdida, podemos evaluar cuán bien o mal lo está haciendo nuestra red neuronal y ajustarla para mejorar su rendimiento.

## 9.2. Error cuadrático medio (MSE)

En este apartado nos enfocaremos en el error cuadrático medio (MSE, por sus siglas en inglés Mean Squared Error), una función de pérdida comúnmente utilizada en el entrenamiento de redes neuronales. Analizaremos cómo se calcula el MSE y por qué es apropiado para ciertos tipos de problemas.

### 9.2.1. ¿Qué es el Error Cuadrático Medio (MSE)?

El error cuadrático medio (MSE) es una medida que nos ayuda a evaluar cuán cerca están las predicciones de un modelo de los valores reales. En otras palabras, el MSE nos dice qué tan bien está funcionando nuestro modelo.

#### Conceptos clave

##### Error
El "error" en el contexto de la ciencia de datos es simplemente la diferencia entre lo que nuestro modelo predijo y lo que realmente ocurrió.

**Ejemplo:** Supón que tienes un modelo que predice el tiempo que tardarás en llegar a casa desde el trabajo. Un día, el modelo predice que tardarás 30 minutos, pero en realidad tardas 40 minutos. Entonces, en este caso, el error sería de 10 minutos.

##### Cuadrático
La palabra "cuadrático" significa que estamos elevando al cuadrado algo. En el caso del MSE, estamos elevando al cuadrado los errores.

**Ejemplo:** Siguiendo con el ejemplo anterior, si el error fue de 10 minutos, el error cuadrático sería 10^2 = 100.

##### Medio
"Medio" significa que estamos calculando el promedio de algo. Para el MSE, estamos promediando los errores cuadrados.

**Ejemplo:** Si tuvimos 5 días de conmutación con errores cuadráticos de 100, 400, 0, 100 y 200, el MSE sería la suma de estos valores (100+400+0+100+200=800) dividido por la cantidad de días (5), lo que nos daría un MSE de 160.

Por lo tanto, el Error Cuadrático Medio es el promedio de los cuadrados de las diferencias entre las predicciones y los valores reales. Su fórmula es la siguiente:

```
MSE = (1/n) * Σ(actual - predicción)^2
```
donde:
- `n` es el número total de observaciones (o puntos de datos),
- `actual` es el valor real,
- `predicción` es el valor que el modelo ha predicho,
- `Σ` indica que sumamos estos valores para todas las observaciones.

### 9.2.2. ¿Por qué se utiliza MSE en el entrenamiento de redes neuronales?

MSE es una función de pérdida comúnmente utilizada en el entrenamiento de redes neuronales porque tiene propiedades que la hacen útil en ciertos contextos, principalmente en problemas de regresión. La regresión se refiere a las tareas donde estamos tratando de predecir un valor numérico continuo, como la temperatura mañana, el precio de una casa, o el tiempo que tardarás en llegar a casa desde el trabajo.

#### Características clave del MSE

1. **Trata de igual manera los errores positivos y negativos:** Al elevar al cuadrado el error, el MSE considera igualmente los errores positivos y negativos. Esto es útil porque a menudo

 nos importa el tamaño del error, pero no su dirección.

**Ejemplo:** Si tu modelo predice que tardarás 30 minutos en llegar a casa y tardas 20 minutos (un error de -10 minutos), o si el modelo predice que tardarás 30 minutos y tardas 40 minutos (un error de 10 minutos), en ambos casos el error cuadrado sería 100.

2. **Penaliza más los errores grandes:** El hecho de elevar al cuadrado el error significa que los errores grandes son penalizados más que los errores pequeños. Esto puede ser útil si es particularmente importante evitar errores grandes.

**Ejemplo:** Imagina que estás tratando de predecir el tiempo que tardarás en llegar al aeropuerto para un vuelo. Un error de 30 minutos (llegar demasiado temprano o demasiado tarde) podría significar perder el vuelo, mientras que un error de 5 minutos probablemente no sea tan grave. En este caso, un modelo con un MSE menor (es decir, con menos errores grandes) sería preferible.

3. **Es diferenciable:** Esto significa que podemos encontrar su derivada, lo que es fundamental para los algoritmos de optimización como el descenso de gradiente, comúnmente utilizado para entrenar redes neuronales.

**Ejemplo:** Veamos cómo se podría calcular el Error Cuadrático Medio (MSE) utilizando la biblioteca de Python `numpy`. Supongamos que tenemos dos listas de Python: una que representa los valores reales y otra que representa las predicciones hechas por nuestro modelo.

Primero, necesitamos importar la biblioteca numpy:

```python
import numpy as np
# Valores reales
valores_reales = [3, -0.5, 2, 7]

# Valores predichos por nuestro modelo
predicciones = [2.5, 0.0, 2, 8]

# Convertir las listas en arrays de numpy
valores_reales = np.array(valores_reales)
predicciones = np.array(predicciones)

# Calcular el MSE
n = len(valores_reales)
mse = np.sum((valores_reales - predicciones) ** 2) / n
print(f"El Error Cuadrático Medio (MSE) es: {mse}")
```

Este código primero calcula la diferencia entre cada par de valores reales y predichos, los eleva al cuadrado y luego suma todos estos valores cuadrados. Esta suma se divide entre el número total de observaciones (n) para obtener el promedio, que es nuestro MSE.

Este es un ejemplo sencillo y práctico de cómo se puede calcular el MSE. En la práctica, sin embargo, es posible que desees utilizar bibliotecas como `scikit-learn` que tienen funciones incorporadas para calcular el MSE y otras métricas comunes.

Es importante recordar que, como cualquier herramienta, el MSE no es perfecto ni es la solución para todo. En algunos casos, otras funciones de pérdida pueden ser más apropiadas. Sin embargo, el MSE es una herramienta útil y ampliamente utilizada en el campo del aprendizaje profundo.

## 9.3. Entropía cruzada (Cross-Entropy)

En esta sección, profundizaremos en la entropía cruzada (cross-entropy), otra función de pérdida utilizada ampliamente en el entrenamiento de redes neuronales. Explicaremos cómo se calcula la entropía cruzada y por qué es especialmente apropiada para problemas de clasificación.

### 9.3.1. ¿Qué es la entropía cruzada?

La entropía cruzada es una medida de la discrepancia entre dos distribuciones de probabilidad. En el contexto del aprendizaje profundo, se utiliza para comparar las predicciones de una red neuronal (distribución de probabilidad predicha) con los valores reales (distribución de probabilidad real).

**Conceptos clave**

#### Entropía cruzada

Es una medida de la similitud entre dos distribuciones de probabilidad. En términos más simples, si tienes dos cestas de frutas, la entropía cruzada te dirá qué tan parecidas son en términos de la distribución de diferentes tipos de frutas que contienen.

**Ejemplo:** Supón que tienes dos cestas de frutas, la cesta A contiene 5 manzanas, 3 peras y 2 naranjas, mientras que la cesta B contiene 7 manzanas, 1 pera y 2 naranjas. La entropía cruzada entre las cestas A y B sería una medida de qué tan parecidas son estas cestas en términos de su contenido de frutas.

### 9.3.2. ¿Cómo se calcula la entropía cruzada?

La entropía cruzada se puede calcular utilizando la siguiente fórmula:

```
H(p, q) = -Σ p(x) log(q(x))
```

donde `p(x)` es la probabilidad real de un evento y `q(x)` es la probabilidad predicha. Esta fórmula simplemente suma las multiplicaciones de las probabilidades reales y el logaritmo de las probabilidades predichas, con un signo negativo al frente.

**Ejemplo de código**

Aquí te muestro cómo puedes calcular la entropía cruzada en Python utilizando la biblioteca Numpy.

```python
import numpy as np

# Probabilidades reales
p = np.array([0.7, 0.2, 0.1])

# Probabilidades predichas
q = np.array([0.6, 0.3, 0.1])

# Entropía Cruzada
cross_entropy = -np.sum(p * np.log(q))

print(f"La entropía cruzada es {cross_entropy}")
```

### 9.3.3. ¿Por qué la entropía cruzada es útil para problemas de clasificación?

La entropía cruzada es especialmente útil en problemas de clasificación debido a su sensibilidad a las discrepancias entre las probabilidades reales y las predichas. Cuando la red neuronal predice una probabilidad muy baja para la clase correcta, la entropía cruzada aumentará significativamente, indicando al modelo que necesita ajustar sus parámetros.

**Ejemplo:** Imagina que estás entrenando una red neuronal para clasificar imágenes de gatos y perros. Si la red predice incorrectamente una probabilidad muy baja (digamos 0.01) para una imagen que es definitivamente un gato, la entropía cruzada de esta predicción será alta. Esto le indicará a la red neuronal que necesita ajustar sus parámetros para mejorar su predicción para imágenes de gatos.

Con esta explicación, deberías tener una comprensión más clara de la entropía cruzada y cómo se utiliza en el entrenamiento de redes neuronales para problemas de clasificación.