## 7. Entrenando y Evaluando el Modelo de tu Red Neuronal
En este capítulo se enseñará cómo entrenar y evaluar el modelo de una red neuronal utilizando los datos de entrenamiento y prueba. Se explicará cómo ajustar los datos de entrada, entrenar el modelo con los datos de entrenamiento, y evaluar la precisión del modelo utilizando los datos de prueba.

## 7.1. Entrenamiento del modelo con los datos de entrenamiento

El entrenamiento es donde alimentamos nuestros datos de entrenamiento al modelo. En este proceso, el modelo intenta aprender patrones útiles en los datos de entrenamiento que le permitirán realizar la tarea en cuestión, como la clasificación de imágenes.

### Conceptos clave

#### Función de pérdida y Optimizador
La función de pérdida es una forma de medir cuán bien se desempeña el modelo en los datos de entrenamiento. Deseamos minimizar esta función para "guiar" el modelo en la dirección correcta.

El optimizador es el algoritmo que utilizamos para minimizar la función de pérdida. Este algoritmo realiza pequeños ajustes a los pesos y sesgos de la red para mejorar su rendimiento.

**Ejemplo:** Puedes imaginar el entrenamiento del modelo como el proceso de aprender a lanzar dardos. Al principio, tus lanzamientos pueden no acertar en el objetivo (alta función de pérdida). Sin embargo, con práctica y ajuste, puedes mejorar tu puntería (minimizar la función de pérdida con un optimizador).

Ahora, procedamos a entrenar nuestro modelo utilizando el siguiente código:

```python
# Definimos el optimizador, la función de pérdida y las métricas que queremos rastrear
model.compile(optimizer='rmsprop', 
              loss='categorical_crossentropy', 
              metrics=['accuracy'])

# Entrenamos el modelo
model.fit(train_data, train_labels, epochs=5, batch_size=128)
```

## 7.2. Evaluación de la precisión del modelo con los datos de prueba

Después de entrenar nuestro modelo, queremos evaluar qué tan bien se desempeña en datos que nunca ha visto antes, a esto lo llamamos datos de prueba. 

### Conceptos clave

#### Evaluación y Precisión
La evaluación es el proceso de verificar qué tan bien se desempeña nuestro modelo en datos que no se utilizaron durante el entrenamiento. La precisión es una medida de cuántas predicciones realizó correctamente el modelo.

**Ejemplo:** Volviendo al ejemplo de lanzar dardos, la evaluación sería como participar en un torneo de dardos después de practicar. Tu puntuación en el torneo (precisión) es una medida de qué tan bien has aprendido a lanzar dardos.

Podemos evaluar la precisión de nuestro modelo con el siguiente código:

```python
# Evaluamos el modelo en los datos de prueba
test_loss, test_acc = model.evaluate(test_data, test_labels)
print('Test accuracy:', test_acc)
```