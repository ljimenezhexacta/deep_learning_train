# 10. Backpropagation: Distribución del Error en la Red Neuronal
En este capítulo se explicará el algoritmo de backpropagation, que es utilizado para distribuir el error de pérdida en una red neuronal y ajustar los pesos de manera adecuada. Se discutirá cómo se propagan los errores desde la capa de salida hasta las capas ocultas y la capa de entrada, utilizando derivadas parciales y la regla de la cadena. Se mostrará cómo se actualizan los pesos de manera iterativa para minimizar la función de pérdida y mejorar el rendimiento del modelo.

## 10.1. ¿Qué es el algoritmo de backpropagation?

El algoritmo de backpropagation es una técnica esencial en el aprendizaje profundo que se utiliza para ajustar los pesos en una red neuronal y distribuir de manera óptima el error de pérdida. Para entenderlo de manera más profunda, dividiremos este concepto en dos partes: el objetivo del algoritmo y su proceso de implementación.

### El objetivo del algoritmo de backpropagation

Las redes neuronales aprenden a partir de los errores que cometen al predecir las salidas. El objetivo del algoritmo de backpropagation es distribuir el "blame" o culpabilidad del error de la salida entre todas las neuronas de la red en función de su contribución a este error.

**Ejemplo:** Piensa en una orquesta tocando una melodía. Si en algún punto suena una nota incorrecta, todo el grupo se ve afectado. Al final del concierto, el director deberá identificar quién o quiénes fueron los responsables de la nota incorrecta y en qué medida contribuyeron a ella. Esta es una analogía de cómo el algoritmo de backpropagation distribuye la culpa del error.

### El proceso de implementación del algoritmo de backpropagation

El algoritmo de backpropagation funciona en dos fases: propagación hacia adelante y propagación hacia atrás.

#### 1. Propagación hacia adelante (Forward Propagation)
En esta fase, la red neuronal hace una pasada hacia adelante, calculando las salidas de cada neurona desde la capa de entrada hasta la capa de salida.

#### 2. Propagación hacia atrás (Backpropagation)
Una vez que tenemos el error de la red (la diferencia entre la salida predicha y la salida real), el proceso de backpropagation comienza. Aquí es donde entran en juego las derivadas parciales y la regla de la cadena.

Primero, se calcula cuánto contribuye cada neurona de la capa de salida al error total, usando la derivada de la función de pérdida con respecto a la salida de la neurona. A continuación, se calcula cuánto contribuyen las neuronas de las capas ocultas a este error, pero esta vez hay que considerar tanto la contribución directa al error como la contribución indirecta a través de las neuronas a las que está conectada en la capa siguiente. Para esto se utiliza la regla de la cadena.

**Ejemplo:** Supongamos que tienes una fábrica de juguetes. Durante la fase de propagación hacia adelante, los trabajadores (neuronas) de cada sección (capa) de la fábrica realizan su trabajo y pasan el producto a la siguiente sección, hasta que el juguete esté terminado (salida de la red). Al final, descubres que hay un error en el juguete terminado. Aquí es donde comienza la fase de backpropagation: debes rastrear hacia atrás para averiguar en qué sección se introdujo el error y cuánto contribuyó cada trabajador a ese error.

Es importante mencionar que después de calcular la contribución de cada neurona al error, se usa esa información para ajustar los pesos de la red neuronal en un proceso llamado "actualización de pesos". Este proceso se repetirá hasta que el error sea lo suficientemente pequeño, o hasta que el modelo deje de mejorar.

## 10.2. Propagación del error en las capas ocultas y de entrada

Cada neurona en las capas ocultas y de entrada contribuye de alguna manera al error total de la red. Durante la backpropagation, se calcula cuánto contribuye cada neurona a este error.

**Ejemplo:** Si piensas en cada pieza de un rompecabezas como una neurona, algunas piezas que están en el lugar incorrecto pueden causar más confusión que otras. Esas piezas son las que más contribuyen al error total, al igual que ciertas neuronas en la red.

### 10.2.1. Derivadas parciales y la regla de la cadena

Las derivadas parciales y la regla de la cadena son dos conceptos matemáticos que se utilizan en la backpropagation para calcular cuánto contribuye cada neurona al error y cómo se deben ajustar los pesos. Aunque puede parecer complicado, se puede pensar en la derivada parcial como una forma de medir cuánto cambia el error cuando se modifica un peso específico, y la regla de la cadena se usa para combinar estas mediciones a través de todas las neuronas de la red.

**Ejemplo:** Si cada pieza del rompecabezas representa un peso en la red, entonces puedes considerar la derivada parcial como una medida de cuánto afectaría al error total mover una pieza específica. La regla de la cadena te ayudaría a entender cómo estos cambios individuales se combinan para afectar al error total.

A continuación, los desglosaremos y te ayudaremos a entenderlos.

#### Derivada Parcial

Una derivada parcial mide cómo cambia una función cuando cambiamos una de sus variables, manteniendo todas las demás constantes. En términos de nuestra red neuronal, la función es la función de error o pérdida, y las variables son los pesos y sesgos de la red. Así que cuando calculamos la derivada parcial de la función de pérdida con respecto a un peso específico, estamos midiendo cuánto cambia el error de la red si cambiamos ese peso un poco, manteniendo todos los demás pesos y sesgos constantes.

**Ejemplo:** Piensa en una receta de pan. Si cambiamos la cantidad de levadura (una variable), la textura del pan (la función) cambiará. La derivada parcial de la textura con respecto a la levadura nos indica cuánto cambiará la textura si cambiamos la cantidad de levadura, mientras que todos los demás ingredientes se mantienen constantes.

Matemáticamente, esto se representa como `∂E/∂w`, que se lee como "la derivada parcial del Error E con respecto al peso `w`".

#### Regla de la cadena

La regla de la cadena es un teorema en cálculo que nos permite calcular la derivada de una función compuesta. En otras palabras, es una forma de descomponer el cálculo de la derivada de una función grande y complicada en cálculos más pequeños y manejables.

En el contexto de las redes neuronales, la regla de la cadena se utiliza para calcular la derivada del error con respecto a los pesos y sesgos a través de múltiples capas de la red.

**Ejemplo:** Imagina que estás en un viaje de varias etapas, comenzando en un tren, luego en un barco y finalmente en un autobús. Si quieres saber cómo un pequeño retraso en el tren (cambio en una variable) afectará a tu hora de llegada final (la función), puedes utilizar la regla de la cadena para descomponer este cálculo. Primero calculas cómo el retraso en el tren afecta a tu hora de llegada al puerto. Luego, calculas cómo llegar tarde al puerto afecta a tu hora de salida en el barco, y así sucesivamente.

Para profundizar un poco más en la regla de la cadena, primero, hay que entender que es un principio básico del cálculo que nos permite encontrar la derivada de funciones compuestas.

Una función compuesta es simplemente una función que tiene otra función dentro de ella. Si tuvieras una función `f(g(x))`, esta sería una función compuesta: `f` es una función que contiene dentro de ella otra función `g`, que a su vez depende de `x`.

La regla de la cadena dice que la derivada de esta función compuesta `(f(g(x)))'` es el producto de la derivada de la función externa evaluada en la función interna `f'(g(x))` y la derivada de la función interna `g'(x)`, esto es:

```
(f(g(x)))' = f'(g(x)) * g'(x)
```

o su equivalente:

```
∂f/∂x = ∂f/∂g * ∂g/∂x
```

**Ejemplo:** Piensa en una función que describe cómo te sientes durante el día. Esta función depende de cuántas horas dormiste la noche anterior y cuánto café has tomado durante el día. Así que si `f` es tu nivel de energía, `g` es las horas de sueño y `h` es la cantidad de café, la función compuesta podría ser `f(g(h(x)))`. La regla de la cadena nos ayudaría a descomponer cómo un cambio en las horas de sueño o la cantidad de café afectaría a tu energía.

Supongamos que la cantidad de café que tomas depende del número de horas que dormiste, y tu energía depende de la cantidad de café que tomaste. Si dormiste pocas horas, es probable que tomes más café, y si tomas más café, es probable que tengas más energía. La regla de la cadena nos ayudaría a calcular cómo un cambio en las horas de sueño afectaría a tu nivel de energía a través de su impacto en la cantidad de café que tomas.

### 10.2.2. Regla de la cadena en redes neuronales

En el contexto de una red neuronal, las derivadas parciales son en realidad derivadas de varias funciones. Para ser más específico, las derivadas están relacionadas con la función de pérdida, la función de activación, y la suma ponderada de las entradas.

Cada neurona toma una entrada, la multiplica por un peso, le añade un sesgo, y luego aplica una función de activación. Luego, la salida de esa neurona se convierte en la entrada para la siguiente, y así sucesivamente hasta que llegamos a la salida de la red. En cada etapa de este proceso, estamos aplicando una función a la salida de la etapa anterior.

Dado que estamos interesados en cómo un pequeño cambio en los pesos o sesgos afecta a la función de pérdida, necesitamos calcular la derivada de la función de pérdida con respecto a los pesos y sesgos.

**Ejemplo:** Consideremos una red neuronal con una capa de entrada, una capa oculta y una capa de salida, y supongamos que omitimos el bias.

Denotando `E` como la función de pérdida, `o` como la salida de la capa de salida, `z` como la suma ponderada de las entradas para la capa de salida, `h` como la salida de la capa oculta, `y` como la suma ponderada de las entradas para la capa oculta, `v` y `w` como los pesos entre la capa oculta y la capa de salida y los pesos entre la capa de entrada y la capa oculta, respectivamente, y `x` la entrada.

Si queremos calcular la derivada de la función de pérdida con respecto a los pesos `v` y `w`, tendríamos que usar la regla de la cadena como:

```
∂E/∂v = ∂E/∂o * ∂o/∂z * ∂z/∂v = ∂E/∂o * ∂o/∂z * h
```

y

```
∂E/∂w = ∂E/∂o * ∂o/∂z * ∂z/∂h * ∂h/∂y * ∂y/∂w = ∂E/∂o * ∂o/∂z * v * ∂h/∂y * x
```

Donde:

- `∂E/∂o` es la derivada de la función de pérdida respecto a la salida de la red, la cual mide cómo un pequeño cambio en la salida de la red afectaría el error.
- `∂o/∂z` es la derivada de la función de activación respecto a la suma ponderada de las entradas, los cual es crucial porque la función de activación es aplicada a `z` para producir la salida `o`.
- `∂z/∂v` es la salida de la capa oculta `h` correspondiente al peso específico `v`, ya que `z` es la suma de las salidas de la capa oculta `h` multiplicada por los pesos `v`.
- `∂z/∂h` es simplemente el peso `v` (por la razón explicada en el punto anterior).
- `∂h/∂y` es la derivada de la función de activación de la capa oculta respecto a la suma ponderada de las entradas de la capa oculta.
- `∂y/∂w` es la entrada `x` correspondiente al peso específico `w`, ya que `y` es simplemente la suma de las entradas multiplicadas por sus respectivos pesos `w`.

Este proceso se aplica para cada neurona en la capa oculta y se repite para cada capa en la red durante el proceso de backpropagation.

## 10.3. Actualización de pesos y minimización de la función de pérdida

A continuación exploraremos cómo se realizan las actualizaciones de los pesos y la minimización de la función de pérdida en el algoritmo de backpropagation. Profundizaremos en técnicas como el descenso de gradiente y cómo estas se utilizan para mejorar el rendimiento de la red neuronal.

### 10.3.1. El uso de Delta (δ)

Al aplicar la regla de la cadena para múltiples capas, nos damos cuenta de que estamos calculando repetidamente las mismas cantidades. Es aquí donde introducimos el concepto de "delta" (δ), que nos ayuda a simplificar este proceso.

Delta es una manera de generalizar el cálculo del error en las redes neuronales. En pocas palabras, delta es una medida de cuánto contribuye un nodo o neurona en una capa oculta al error total. Así, podemos decir que delta es el "error" asociado a cada neurona.

**Ejemplo:** Imagina que eres el entrenador de un equipo de relevos. Para mejorar el rendimiento del equipo, necesitas saber cuánto contribuye cada corredor al tiempo total. Si un corredor es especialmente lento, puedes centrarte en mejorar su rendimiento para reducir el tiempo total. En este caso, el delta sería como el tiempo adicional que cada corredor añade al tiempo total.

#### Delta en la capa final

El cálculo del delta en la capa final es sencillo, ya que podemos medir directamente cuánto contribuye cada neurona al error total. Este delta se calcula simplemente como la derivada de la función de pérdida con respecto a la salida de la red, multiplicada por la derivada de la función de activación aplicada a la suma ponderada de las entradas.

En términos matemáticos, podemos definir el delta en la capa de salida como:

```
δ_output = ∂E/∂o * ∂o/∂z
```

Donde `δ_output` es el delta para la capa de salida, `∂E/∂o` es la derivada de la función de pérdida con respecto a la salida de la red, `∂o/∂z` es la derivada de la función de activación aplicada a la suma ponderada de las entradas.

#### Delta en las capas ocultas

Calcular el delta en las capas ocultas es un poco más complicado, ya que no podemos medir directamente su contribución al error total. Sin embargo, podemos usar los deltas de la capa siguiente para calcularlo. Para ello, tomamos el delta de la capa siguiente, multiplicamos cada delta por el peso correspondiente que conecta la neurona de la capa oculta con la neurona de la capa siguiente, y luego sumamos estos productos. Finalmente, multiplicamos este total por la derivada de la función de activación aplicada a la suma ponderada de las entradas de la neurona de la capa oculta.

Para ello, podemos usar la siguiente fórmula:

```
δ_i = (∑ weights_ij * δ_j) * ∂a_i/∂z_i
```

Donde `δ_i` es el delta de la i-ésima neurona, `weights_ij` son los pesos que conectan la i-ésima neurona con la j-ésima neurona en la siguiente capa, `δ_j` es el delta de la j-ésima neurona en la siguiente capa, `∂a_i/∂z_i` es la derivada de la función de activación aplicada a la suma ponderada de las entradas de la i-ésima neurona.

#### Generalización de los deltas

La belleza del cálculo de los deltas es que es recursivo: una vez que hemos calculado los deltas para la capa final, podemos usarlos para calcular los deltas de la capa anterior, y así sucesivamente hasta la primera capa oculta. Esta generalización simplifica enormemente el proceso de propagación del error.

#### Cálculo de las derivadas respecto a los pesos y biases

Una vez que tenemos los deltas, podemos usarlos para calcular las derivadas de la función de pérdida respecto a los pesos y los biases. Estas derivadas nos dirán cuánto cambia la función de pérdida si cambiamos ligeramente un peso o un bias.

```
∂E/∂w = δ * input
∂E/∂b = δ
```

### 10.3.1. Actualización de pesos con el descenso de gradiente

#### Actualización de los pesos y biases

La actualización de pesos es un proceso por el cual los pesos asociados a las conexiones entre las neuronas de una red neuronal se ajustan para reducir el error de predicción.

Podemos usar las derivadas calculadas en el paso anterior para actualizar los pesos y los biases. Para ello, restamos a cada peso y bias una pequeña fracción `η` de la derivada correspondiente. 

```
w = w - η * ∂E/∂w
b = b - η * ∂E/∂b
```

Este proceso se llama descenso de gradiente y es la manera en que la red neuronal aprende a minimizar la función de pérdida y, por lo tanto, a mejorar su rendimiento, donde `η` es la tasa de aprendizaje (o learning rate), un hiperparámetro que controla cuánto cambiamos los pesos en cada actualización.

**Ejemplo:** Siguiendo con el ejemplo del equipo de relevos, podrías ver el tiempo de cada corredor como los pesos de la red neuronal. A medida que entrenas al equipo, ajustas estos tiempos para minimizar el tiempo total (la función de pérdida). Al igual que en el descenso de gradiente, puedes hacer pequeños ajustes en el entrenamiento de cada corredor (actualizar los pesos) para mejorar el rendimiento del equipo.

**Ejemplo:** Piensa en la actualización de pesos como afinar los instrumentos en una orquesta. Cada instrumento (peso) contribuye a la armonía general (predicción). Si un instrumento está desafinado (error de predicción alto), se ajusta (actualiza el peso) para mejorar la armonía.

Para actualizar los pesos, utilizamos las derivadas de la función de pérdida con respecto a cada peso.

#### Descenso de gradiente
El descenso de gradiente es un método de optimización que se utiliza para minimizar la función de pérdida ajustando iterativamente los pesos en la dirección opuesta al gradiente.

Esta técnica es la más comúnmente utilizada para actualizar los pesos en una red neuronal. Esta técnica utiliza el gradiente de la función de pérdida para actualizar cada peso en una dirección que reduzca la pérdida.

**Ejemplo:** Imagina que estás en la cima de una colina y quieres llegar al fondo (minimizar la función de pérdida). No puedes ver toda la colina a la vez, así que en cada paso, te mueves en la dirección que parece más empinada hacia abajo (el gradiente). Esto te llevará eventualmente al fondo de la colina.

#### Rendimiento del modelo
El rendimiento del modelo se refiere a qué tan bien la red neuronal puede hacer predicciones correctas basándose en los datos de entrada.

El objetivo final de la actualización de pesos y la minimización de la función de pérdida es mejorar el rendimiento del modelo de la red neuronal. A medida que los pesos se ajustan y la pérdida se minimiza, el modelo se vuelve mejor para predecir los resultados correctos basándose en los datos de entrada.

**Ejemplo:** Piensa en el rendimiento del modelo como tu puntuación en un videojuego. A medida que mejoras (ajustas los pesos y minimizas la función de pérdida), tu puntuación (rendimiento del modelo) se eleva.
