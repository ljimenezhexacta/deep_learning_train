# 9. Descenso del Gradiente: Optimizando los Pesos de la Red Neuronal
Aquí se introducirá el concepto de descenso del gradiente, que es un algoritmo utilizado para optimizar los pesos de una red neuronal y encontrar los mínimos de la función de pérdida. Se discutirá la importancia del learning rate y el momentum en el proceso de optimización, y cómo afectan la convergencia y la eficiencia del modelo.

## 9.1. Introducción al descenso del gradiente

El descenso del gradiente es un algoritmo de optimización que busca los mínimos de una función, en nuestro caso, la función de pérdida o error de nuestra red neuronal. La idea es ajustar los pesos en la dirección opuesta al gradiente para reducir el error. A continuación, desglosaremos estos conceptos para una mejor comprensión.

### Conceptos clave

#### Gradiente
El gradiente es una medida de cómo una función cambia si alteras sus variables. En el contexto de las redes neuronales, representa la dirección y la tasa a la que el error de nuestro modelo cambia con respecto a los pesos.

**Ejemplo:** Imagina que estás en una montaña y tu objetivo es llegar al valle más cercano. Puedes sentir el terreno con tus pies y determinar en qué dirección está la pendiente más pronunciada. Esa es la dirección en la que debes moverte para descender más rápido. En este caso, la pendiente del terreno es análoga al gradiente.

#### Función de pérdida
La función de pérdida, también conocida como función de error, es una medida de qué tan bien el modelo de red neuronal está funcionando. El objetivo es minimizar el valor de esta función, lo que significa que queremos que nuestro modelo cometa la menor cantidad de errores posible.

**Ejemplo:** Supón que estás jugando a los dardos y tu objetivo es acertar al centro. Cada vez que lanzas un dardo, mides la distancia desde donde cayó hasta el centro. Esa distancia es tu error o pérdida. Quieres que esta distancia sea lo más pequeña posible.

#### Ajuste de pesos
El ajuste de pesos en una red neuronal es el proceso de cambiar los valores de los pesos basándose en la información del gradiente. La idea es moverse en la dirección opuesta al gradiente para reducir el error y mejorar la precisión del modelo.

**Ejemplo:** Imagina que estás afinando un instrumento musical. Cada vez que tocas una nota, puedes escuchar si está demasiado alta o demasiado baja. Entonces ajustas la tensión de la cuerda (el "peso") en la dirección opuesta para acercarte al tono correcto.

### Descenso del gradiente en acción

Ahora que tenemos una idea de los componentes clave, veamos cómo se aplica el descenso del gradiente en una red neuronal. En cada paso de nuestro entrenamiento, calculamos el gradiente de la función de pérdida con respecto a los pesos. Luego, ajustamos los pesos en la dirección opuesta al gradiente.

Este proceso se repite varias veces, y cada vez, nuestro modelo se acerca más a la función objetivo, es decir, a minimizar el error. La eficacia de este proceso depende de factores como el learning rate y el momentum.

## 9.2. Learning rate y su impacto en la optimización

El learning rate es uno de los hiperparámetros más importantes en el proceso de optimización mediante el descenso del gradiente. En esta sección, desglosaremos su papel y cómo su ajuste puede afectar la velocidad de convergencia y la eficiencia del modelo. 

### 9.2.1 ¿Qué es el Learning rate?

El Learning rate (tasa de aprendizaje) es un hiperparámetro que determina cuánto se ajustan los pesos en cada iteración del entrenamiento de una red neuronal. Su valor influye en cuánto cambiamos los pesos de la red en la dirección opuesta al gradiente de la función de pérdida.

**Ejemplo:** Piensa en el learning rate como el tamaño de los pasos que das mientras desciendes de una montaña. Si das pasos muy grandes (alto learning rate), podrías bajar más rápido, pero también podrías saltarte el camino óptimo o incluso caer. Por otro lado, si das pasos pequeños (bajo learning rate), te tomará más tiempo llegar al fondo, pero tendrás más posibilidades de encontrar el camino óptimo.

### 9.2.2. Impacto del Learning rate en la convergencia y eficiencia del modelo

El Learning rate tiene un papel crítico en la convergencia y la eficiencia del modelo. Un learning rate muy alto podría hacer que el modelo converja muy rápidamente, pero a costa de posiblemente saltarse el mínimo global de la función de pérdida. En contraste, un learning rate muy pequeño puede conducir a una convergencia muy lenta o incluso a la posibilidad de que el modelo no converja en absoluto.

**Ejemplo:** Imagina que estás tratando de adivinar el peso de una manzana. Si cambias tu estimación en grandes cantidades (alto learning rate), podrías estar muy cerca del peso real muy rápidamente, pero también podrías saltarte el peso correcto. Si cambias tu estimación en pequeñas cantidades (bajo learning rate), es posible que te acerques lentamente al peso correcto, pero podrías tardar mucho tiempo en llegar allí.

### 9.2.3. Ajuste del Learning rate

El ajuste del learning rate es un desafío en el entrenamiento de redes neuronales. Un learning rate demasiado grande puede hacer que el modelo diverja y no aprenda correctamente. Por otro lado, un learning rate demasiado pequeño puede hacer que el entrenamiento sea demasiado lento y que el modelo se atasque en un mínimo local en lugar de encontrar el mínimo global.

**Ejemplo:** Volviendo al ejemplo de la montaña, si das pasos muy grandes, podrías caer en un pozo pequeño (mínimo local) y ser incapaz de salir, perdiéndote el valle grande y profundo más adelante (mínimo global). Si das pasos muy pequeños, podrías evitar los pozos pequeños, pero podrías tardar demasiado tiempo en llegar al gran valle.

El learning rate es un hiperparámetro crucial en el entrenamiento de las redes neuronales. Su ajuste correcto puede marcar la diferencia entre un modelo que aprende de manera eficiente y uno que no aprende en absoluto o que aprende muy lentamente.

## 9.3. Momentum: acelerando la optimización

El momentum es un término que se ha incorporado al algoritmo del descenso del gradiente para acelerar el proceso de optimización y evitar quedar atrapados en mínimos locales. Este concepto proviene de la física, más precisamente de la ley del movimiento de Newton, y permite ganar "impulso" en la dirección correcta durante la optimización de la red neuronal. Vamos a desglosar este concepto para comprenderlo mejor.

### Conceptos clave

#### Momentum

El momentum en el contexto de las redes neuronales se refiere a la idea de dar un impulso a la actualización de los pesos durante el entrenamiento, de manera que se acelere la convergencia y se puedan superar los mínimos locales en la superficie del error.

**Ejemplo:** Piensa en una bola rodando cuesta abajo. Inicialmente, la bola empieza a rodar lentamente, pero a medida que continúa rodando, su velocidad aumenta debido al momentum. Esto es similar a cómo el descenso del gradiente con momentum acelera la optimización.

#### Mínimos locales

Los mínimos locales son puntos de la función de error donde el valor es más pequeño que en los puntos circundantes, pero no necesariamente es el mínimo global de toda la función. Estos puntos pueden causar problemas durante el entrenamiento de una red neuronal, ya que el modelo puede quedar atrapado en ellos y no encontrar el mínimo global, que correspondería a la mejor solución.

**Ejemplo:** Imagina que estás en un valle rodeado de montañas. Desde tu punto de vista, parece que estás en el punto más bajo, pero si logras escalar una de las montañas, podrías darte cuenta de que hay otros valles más bajos. En este caso, el valle donde te encuentras es un mínimo local, pero no el global.

#### Actualización de los pesos

Durante el entrenamiento de una red neuronal, los pesos se actualizan iterativamente con el fin de minimizar el error. Esta actualización se realiza generalmente en la dirección opuesta al gradiente (descenso del gradiente). El momentum ayuda a dar un impulso a estas actualizaciones, acelerando el proceso y ayudando a superar los mínimos locales.

**Ejemplo:** Si estás intentando encontrar el camino más corto en una ciudad desconocida, podrías empezar caminando en una dirección al azar, pero si te das cuenta de que te estás alejando de tu destino, cambiarías la dirección. Aquí, cada cambio de dirección es una "actualización" en tu camino. El momentum sería como un viento a tu favor que te ayuda a moverte más rápido hacia tu destino.
