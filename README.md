# Deep Learning

## Redes Neuronales

| Tema | Descripción | Herramientas |
|------|-------------|--------------|
| 1. Introducción a las Redes Neuronales Artificiales | En este tema se explorarán las redes neuronales artificiales, que son modelos inspirados en el cerebro humano para el procesamiento de información. Aprenderás los conceptos básicos de las redes neuronales, su estructura y funcionamiento, y cómo se utilizan en el campo del aprendizaje profundo. | - |
| 2. Herramientas para el Desarrollo de Redes Neuronales | En esta sección se presentarán las herramientas más comunes utilizadas en el desarrollo de redes neuronales. Se abordarán temas como la API Keras, que proporciona una interfaz de alto nivel para la construcción de redes neuronales, y los backends populares como TensorFlow, Theano y CNTK. También se discutirán las bibliotecas de bajo nivel como CuDA, cuDNN, BLAS y Eigen, así como las opciones de hardware como GPU y CPU. | Keras, TensorFlow, Theano, CNTK, CuDA, cuDNN, BLAS, Eigen, GPU, CPU |
| 3. Introducción al Deep Learning | En este tema se introducirá el concepto de deep learning y su relación con la inteligencia artificial y el machine learning. Se explicarán las diferencias entre estos tres términos y se explorarán las ventajas y aplicaciones del deep learning en diversas áreas. | - |
| 4. Comparación entre el Machine Learning Tradicional y el Deep Learning | En esta sección se compararán los enfoques del machine learning tradicional y el deep learning. Se analizará el flujo de trabajo típico en ambos enfoques, desde la ingeniería de características hasta la clasificación de datos, destacando cómo el deep learning integra el aprendizaje de características y la clasificación en una sola etapa. | - |
| 5. Problemas Comunes en Deep Learning | En este tema se abordarán dos problemas comunes en el deep learning: el overfitting (sobreajuste) y la caja negra. Se explicará qué es el overfitting y cómo evitarlo, así como las limitaciones de interpretación de las redes neuronales como cajas negras. | - |
| 6. Construyendo tu Primera Red Neuronal con Keras | En esta sección se guiará al estudiante a través del proceso de construcción de su primera red neuronal utilizando la biblioteca Keras. Se explicará cómo cargar y preprocesar conjuntos de datos, construir una arquitectura de red neuronal básica, compilar el modelo y ajustar los datos. Se utilizará el ejemplo de reconocimiento de dígitos utilizando el conjunto de datos MNIST. | Keras, numpy, matplotlib.pyplot |
| 7. Entrenando y Evaluando el Modelo de tu Red Neuronal | En este tema se enseñará cómo entrenar y evaluar el modelo de una red neuronal utilizando los datos de entrenamiento y prueba. Se explicará cómo ajustar los datos de entrada, entrenar el modelo con los datos de entrenamiento, y evaluar la precisión del modelo utilizando los datos de prueba. | - |
| 8. La Neurona: La Unidad Básica de una Red Neuronal | En esta sección se profundizará en el concepto de la neurona, que es la unidad básica de una red neuronal. Aquí se explorará en detalle la estructura y el funcionamiento de una neurona artificial en una red neuronal. Se abordarán conceptos como las entradas, los pesos, las sumas ponderadas, las funciones de activación y las salidas de una neurona. Se explicará cómo se realiza el cálculo de una neurona y cómo contribuye a la predicción final del modelo. | - |
| 9. Ejemplo Práctico: Compuertas Lógicas con Perceptrones | En este ejemplo práctico se mostrará cómo los perceptrones, una forma básica de redes neuronales, pueden resolver problemas simples de lógica booleana. Se utilizarán las compuertas AND, OR y XOR para ilustrar las capacidades y limitaciones de los perceptrones. | - |
| 10. Arquitectura de una Red Neuronal | En esta sección se explorará la arquitectura general de una red neuronal. Se discutirán los conceptos de capa de entrada, capas ocultas y capa de salida, así como las características generales y específicas de cada una. Se explicará cómo las redes neuronales están compuestas por matrices y vectores, y cómo se realiza el producto matricial y se aplica el sesgo (bias). | - |
| 11. Funciones de Activación en las Redes Neuronales | Aquí se estudiarán las funciones de activación utilizadas en las redes neuronales. Se presentarán diferentes tipos de funciones, incluyendo las discretas y las continuas, como la función escalón, la función signo, la función sigmoidal, la función tangente hiperbólica, la función lineal rectificada (ReLU) y la función softmax. Se explicará el propósito y la aplicabilidad de cada función en el contexto de una red neuronal. | - |
| 12. Función de Pérdida en el Entrenamiento de Redes Neuronales | En esta sección se abordará la función de pérdida, que es utilizada en el entrenamiento de redes neuronales para evaluar la discrepancia entre las predicciones del modelo y los valores reales. Se explorarán dos funciones de pérdida comunes: el error cuadrático medio (MSE) y la entropía cruzada (cross-entropy). Se explicará cómo se calculan y su relevancia en diferentes tareas de aprendizaje. | - |
| 13. Descenso del Gradiente: Optimizando los Pesos de la Red Neuronal | Aquí se introducirá el concepto de descenso del gradiente, que es un algoritmo utilizado para optimizar los pesos de una red neuronal y encontrar los mínimos de la función de pérdida. Se discutirá la importancia del learning rate y el momentum en el proceso de optimización, y cómo afectan la convergencia y la eficiencia del modelo. | - |
| 14. Backpropagation: Distribución del Error en la Red Neuronal | En esta sección se explicará el algoritmo de backpropagation, que es utilizado para distribuir el error de pérdida en una red neuronal y ajustar los pesos de manera adecuada. Se discutirá cómo se propagan los errores desde la capa de salida hasta las capas ocultas y la capa de entrada, utilizando derivadas parciales y la regla de la cadena. Se mostrará cómo se actualizan los pesos de manera iterativa para minimizar la función de pérdida y mejorar el rendimiento del modelo. | - |
| 15. Playground de Tensorflow: Explorando Redes Neuronales | En esta sección se utilizará el Playground de Tensorflow, una herramienta interactiva en línea, para explorar y experimentar con redes neuronales. Se presentará la interfaz y se realizarán diferentes configuraciones y ajustes en la red neuronal para observar su impacto en el rendimiento y la precisión del modelo. | Tensorflow, Playground de Tensorflow |


## Redes Neuronales con Python

| Tema | Descripción | Herramientas |
|---|---|---|
| 1. Introducción al Aprendizaje Profundo | En este tema te adentrarás en el fascinante mundo del Aprendizaje Profundo. Aprenderás los conceptos fundamentales y cómo se aplican en la resolución de problemas complejos. Descubrirás cómo las redes neuronales pueden imitar el funcionamiento del cerebro y realizar tareas como reconocimiento de imágenes, procesamiento de lenguaje natural y más. | - |
| 2. Fundamentos de las Redes Neuronales | Aquí exploraremos los componentes esenciales de las redes neuronales. Conocerás los conceptos de neuronas, pesos, funciones de activación y capas. Veremos cómo se realiza la propagación hacia adelante para obtener resultados y cómo los parámetros de la red influyen en su desempeño. | - |
| 3. Dimensiones y Estructura de los Datos | En este tema entenderemos las dimensiones de los datos en Aprendizaje Profundo. Desde escalares hasta tensores, exploraremos cómo se representan diferentes tipos de datos y cómo influyen en el diseño de modelos. Veremos ejemplos prácticos de matrices y tensores en imágenes y series de tiempo. | Python, numpy |
| 4. Preparación de los Datos | La calidad de los datos es crucial en el Aprendizaje Profundo. Aprenderás técnicas para limpiar, normalizar y transformar los datos antes de alimentarlos a una red neuronal. Veremos cómo manejar valores faltantes, codificar variables categóricas y dividir conjuntos de datos en entrenamiento y prueba. | Python, numpy |
| 5. Construyendo una Red Neuronal desde Cero | En este tema te sumergirás en la implementación de una red neuronal utilizando solo numpy y matemáticas. Desde la inicialización de parámetros hasta el entrenamiento y la predicción, conocerás cada paso del proceso. Analizaremos funciones de activación, función de pérdida y descenso del gradiente. | Python, numpy |
| 6. Entrenamiento y Evaluación del Modelo | Aquí aprenderás a entrenar y evaluar tu modelo de Aprendizaje Profundo. Exploraremos el proceso de propagación hacia adelante, cálculo del error, retropropagación y actualización de los parámetros. Veremos cómo ajustar hiperparámetros como el learning rate y las épocas para obtener mejores resultados. | Python, numpy |
| 7. Optimización y Regularización | La optimización y regularización son técnicas clave para mejorar el rendimiento de los modelos de Aprendizaje Profundo. Aprenderás sobre optimizadores como el descenso del gradiente estocástico y la regularización L1 y L2. Veremos cómo prevenir el sobreajuste y mejorar la generalización del modelo. | Python, numpy |
| 8. Aplicaciones del Aprendizaje Profundo | En este tema exploraremos diversas aplicaciones del Aprendizaje Profundo en la vida cotidiana. Desde reconocimiento de voz hasta conducción autónoma, descubrirás cómo esta poderosa tecnología está transformando diferentes industrias. Analizaremos casos de éxito y desafíos futuros en el campo del Aprendizaje Profundo. | - |